# Projeto de Pipeline de Dados com HDFS/Hive - Processos Jur√≠dicos

![Linguagem](https://img.shields.io/badge/Linguagem-Python%20%7C%20HQL-blue)
![Tecnologia](https://img.shields.io/badge/Tecnologias-HDFS%20%7C%20Hive%20%7C%20Jupyter-yellow)
![Arquitetura](https://img.shields.io/badge/Arquitetura-Medallion%20(B%7CS%7CG)-brightgreen)
![Licen√ßa](https://img.shields.io/badge/Licen%C3%A7a-MIT-lightgrey)

## üìú Vis√£o Geral

Este projeto demonstra um pipeline completo de processamento de dados em batch, simulando o tratamento de um grande volume de dados processuais. O fluxo de trabalho engloba desde a ingest√£o de dados brutos at√© a cria√ß√£o de tabelas anal√≠ticas agregadas, prontas para consumo por ferramentas de Business Intelligence ou an√°lise de dados.

A arquitetura utilizada √© a **Medallion Architecture**, que organiza os dados em tr√™s camadas l√≥gicas: **Bronze** (bruto), **Silver** (limpo e transformado) e **Gold** (agregado e pronto para neg√≥cio).

---

## üèóÔ∏è Arquitetura do Pipeline

O fluxo de dados foi desenhado para garantir rastreabilidade, qualidade e performance, seguindo as etapas abaixo:

![Pipeline](pipeline.png)


1.  **Ingest√£o (Python/Jupyter)**: O notebook `Ingestao.ipynb` realiza o pr√©-processamento inicial, tratando inconsist√™ncias e gerando um arquivo CSV limpo.
2.  **Carregamento no HDFS**: O CSV √© transferido para o HDFS, servindo como fonte para a primeira camada do Data Lake.
3.  **Camada Bronze**: Os dados s√£o armazenados em seu formato bruto, como uma c√≥pia fiel da origem, garantindo um ponto de recupera√ß√£o.
4.  **Camada Silver**: Os dados s√£o limpos, transformados, enriquecidos e particionados para otimizar consultas futuras.
5.  **Camada Gold**: Os dados da camada Silver s√£o agregados para criar modelos de dados espec√≠ficos para as necessidades de neg√≥cio, como KPIs e m√©tricas de performance.

---

## üõ†Ô∏è Tecnologias Utilizadas

*   **Ingest√£o e Pr√©-processamento**: Python 3.12, Pandas, Jupyter Notebook
*   **Armazenamento Distribu√≠do**: HDFS (Hadoop Distributed File System)
*   **Data Warehousing e ETL**: Apache Hive (HiveQL)
*   **Formato de Armazenamento**: Parquet (para camadas Silver e Gold)

---